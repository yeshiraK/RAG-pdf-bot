{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "z1l_y34lYp_5",
        "outputId": "aba5fb57-3016-44f2-f4e0-1594844c0518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m631.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m340.6/340.6 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m804.0/804.0 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "pymc 5.21.2 requires rich>=13.7.1, but you have rich 13.4.2 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade langchain langchain_google_genai langchain-core langchain_community docs2txt pypdf langchain_chroma sentence_transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo_4IZipMY_M"
      },
      "source": [
        "##**What is Retrieval Augmented Generation (RAG)?**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP_y8KpHOGHz"
      },
      "source": [
        "###**LangChain Components and Expression Language (LCEL)**\n",
        "1. Large Language Model (LLM)\n",
        "2. Output Parsers\n",
        "3. Structured Output\n",
        "4. Prompt Templates\n",
        "5. LLM Messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8RLGDPJYGsB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"]=\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCB54yqcYRkX"
      },
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
        "os.environ['LANGCHAIN_API_KEY']=\"\"\n",
        "os.environ['LANGCHAIN_PROJECT']=''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHEqUfrLYuEu",
        "outputId": "9bc424b4-10c5-4e9f-a416-d8fb0d65a4fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Why do programmers prefer dark mode?\\n\\nBecause light attracts bugs!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run-466d6a03-dd88-4ce6-8248-c4b4adc820a0-0', usage_metadata={'input_tokens': 8, 'output_tokens': 14, 'total_tokens': 22, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm=ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
        "llm_response=llm.invoke(\"Tell me a simple joke about coding!\")\n",
        "llm_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nmzII1DvZXFT",
        "outputId": "0b079d60-a38c-4dbe-d630-019f1eb08f30"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Why do programmers prefer dark mode?\\n\\nBecause light attracts bugs!'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "output_parser=StrOutputParser()\n",
        "output_parser.invoke(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "QyS-55JkZpID",
        "outputId": "57b6de46-8e54-4cd4-c6a3-b10ecb906d94"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Elara, a clockwork raven with emerald eyes, perched on the spire of the Grand Obsidian Clocktower.  Her gears whirred softly, a counterpoint to the booming chime that announced the hour – midnight.  Below, the city of Aethelburg glittered, a tapestry woven with gaslight and shadow.  Elara wasn't like the other clockwork creations; she possessed a spark of something more, a flicker of sentience that the master clockmaker, old Silas, had accidentally imbued into her during her creation.\\n\\nSilas, a recluse with a beard like tangled wires, had tasked Elara with a vital duty: guarding the Chronarium, a heart-shaped crystal housed within the tower that regulated the city's time.  Without it, Aethelburg would descend into temporal chaos.\\n\\nTonight, however, something felt different.  A tremor, not in the earth, but in the very fabric of time, rippled through the tower.  Elara's internal mechanisms sputtered, her emerald eyes widening.  From the shadows below, a figure emerged – a cloaked woman with eyes like chips of obsidian, her hand clutching a wickedly curved dagger that shimmered with an unnatural light.\\n\\nThe woman, a time thief known only as Nyx, moved with a grace that defied gravity, scaling the tower with unnerving speed.  She sought the Chronarium, intending to steal fragments of time to sell on the black market, creating paradoxes and altering history for profit.\\n\\nElara launched herself into the air, her brass wings beating a furious rhythm.  The ensuing battle was a whirlwind of gears and shadows, of clockwork precision against the unpredictable magic of Nyx.  Elara’s beak, sharpened to a point, clashed against Nyx’s dagger, sparks showering from the impact.  Nyx’s magic disrupted Elara’s internal mechanisms, causing her to stumble.\\n\\nJust as Nyx reached for the Chronarium, Silas, alerted by the disturbance, burst from his workshop.  He wasn’t a fighter, but he possessed an understanding of time's intricacies that surpassed even Nyx's.  With a whispered incantation and a flick of his wrist, he manipulated the very flow of time around Nyx, slowing her movements to a crawl.\\n\\nElara, seizing the opportunity, pecked at Nyx’s hand, forcing her to drop the dagger.  Silas secured the Chronarium, and Nyx, her power neutralized, was apprehended by the city guard.\\n\\nAs dawn broke, painting the sky in hues of rose and gold, Elara perched on the spire once more, her gears whirring smoothly.  The city below awoke, unaware of the temporal crisis averted, its time flowing steadily thanks to the brave clockwork raven and her eccentric creator.  Elara knew her secret, her sentience, remained safe.  And as the Grand Obsidian Clocktower chimed the hour, she felt a quiet satisfaction – the guardian of time had done her duty.\""
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain=llm | output_parser\n",
        "chain.invoke(\"Tell me a story!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7zo3pencQ0k",
        "outputId": "90610363-0cef-4e9d-fa78-052aa9522c71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "topic='\"Dynamic Programming\"' summary='\"Mind-blowing topic, but tough at first. Requires a lot of practice and can be confusing at times.\"' rating=4.5 pros=['\"Optimizes recursive solutions\"', '\"Efficient for overlapping subproblems\"', '\"Game-changer for problem-solving\"']\n",
            "['\"Optimizes recursive solutions\"', '\"Efficient for overlapping subproblems\"', '\"Game-changer for problem-solving\"']\n"
          ]
        }
      ],
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel,Field\n",
        "\n",
        "class ReviewDSA(BaseModel):\n",
        "  topic:str=Field(description=\"Name of the DSA topic\")\n",
        "  summary: str=Field(description=\"Brief summary of the review\")\n",
        "  rating: float=Field(description=\"Overall rating out of 5\")\n",
        "  pros: List[str]=Field(description=\"List of positive aspects\")\n",
        "\n",
        "\n",
        "prompt_text='''\n",
        " Just started learning Dynamic Programming, and wow, this topic is mind-blowing! The way it optimizes\n",
        "    recursive solutions is just amazing. It really helps in solving problems efficiently that involve\n",
        "    overlapping subproblems, like Fibonacci and Knapsack.\n",
        "\n",
        "    But not gonna lie, it's tough at first. You really need to practice a lot to get the hang of thinking\n",
        "    in terms of subproblems. Also, memorization techniques can be confusing, and it’s easy to mess up\n",
        "    the transition from recursion to tabulation.\n",
        "\n",
        "    Overall, I'd rate it a 4.5 out of 5. Once you get it, it’s a game-changer for problem-solving.\n",
        "    Definitely worth the effort!\n",
        "'''\n",
        "\n",
        "structured_llm=llm.with_structured_output(ReviewDSA)\n",
        "output=structured_llm.invoke(prompt_text)\n",
        "print(output)\n",
        "print(output.pros)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtbUns1PdxJZ",
        "outputId": "78d48f3e-aa52-41f4-bfa9-a07537ec8aeb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content='Tell me a joke about sports', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt=ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
        "prompt.invoke({\"topic\":\"sports\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO_qAo5FeSN9",
        "outputId": "bea83705-3e18-4db2-c95b-87901db71876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Why do programmers prefer dark mode?\n",
            "\n",
            "Because light attracts bugs!\n"
          ]
        }
      ],
      "source": [
        "chain=prompt | llm|output_parser\n",
        "result=chain.invoke({\"topic\":\"coding\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfFKwB6teoW_",
        "outputId": "5a029f79-b230-4970-a76d-9ee75fa4b073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='Why do programmers prefer dark mode?\\n\\nBecause light attracts bugs!' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []} id='run-a7f51658-77e7-4607-902f-01546818b4c5-0' usage_metadata={'input_tokens': 15, 'output_tokens': 14, 'total_tokens': 29, 'input_token_details': {'cache_read': 0}}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage,SystemMessage\n",
        "\n",
        "messages=[\n",
        "    SystemMessage(content=\"You are a helpful coding assistant!\"),\n",
        "    HumanMessage(content=\"Tell me a joke about Debugging in code\")\n",
        "]\n",
        "\n",
        "response=llm.invoke(messages)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrUwomcCfSrV",
        "outputId": "38f771f8-9fca-49bc-ce79-8758e0986205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='Why do programmers prefer dark mode?\\n\\nBecause light attracts bugs!' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []} id='run-a2c90a6b-3d08-485e-8299-a57a86de21da-0' usage_metadata={'input_tokens': 12, 'output_tokens': 14, 'total_tokens': 26, 'input_token_details': {'cache_read': 0}}\n"
          ]
        }
      ],
      "source": [
        "template=ChatPromptTemplate([\n",
        "    (\"system\",\"You are a helpful coding assistant\"),\n",
        "    (\"human\",\"tell me a joke about {topic}\")\n",
        "])\n",
        "\n",
        "chain=template | llm\n",
        "result=chain.invoke({\"topic\":\"coding\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5ugOJQdlY5P",
        "outputId": "42a5b82d-d0b5-42d4-cdc7-337c196fc6ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Docx2txt in /usr/local/lib/python3.11/dist-packages (0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install Docx2txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhrFua_-OJFH"
      },
      "source": [
        "###**Document Processing**\n",
        "- Loading Documents\n",
        "- Splitting Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkrSRyMZlYcx",
        "outputId": "baf0beba-932f-46fe-ba6c-5ed90623f3e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "splitted with 10 chunks\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader,Docx2txtLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from typing import List\n",
        "from langchain_core.documents import Document\n",
        "import os\n",
        "\n",
        "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200,length_function=len)\n",
        "\n",
        "docx_loader=Docx2txtLoader(\"/content/docs/SUPRATIMNAG_AIML.docx\")\n",
        "documents=docx_loader.load()\n",
        "\n",
        "\n",
        "splits=text_splitter.split_documents(documents)\n",
        "print(f\"splitted with {len(splits)} chunks\")\n",
        "print(len(documents))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQtVbCV6mk1L",
        "outputId": "5c451af9-d6b9-46b2-ac3a-089fe444377f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/docs/SUPRATIMNAG_AIML.docx'}, page_content='Supratim Nag\\n\\nHowrah,West Bengal, India\\n\\n\\uf10b (+91) 8420945255 | snsupratim@gmail.com | https://github.com/snsupratim | snsupratim-portfolio |  https://www.linkedin.com/in/snsupratim\\uf08c\\n\\n\\n\\nSummary ---------------------------------------------------------------------------------\\n\\n\\n\\nEnthusiastic and detail-oriented B.Tech student in Computer Science and Engineering with a specialization in Artificial Intelligence and Machine Learning. Actively learning machine learning, deep learning, NLP, and generative AI techniques. Also worked with various tech stack to built full-stack web application .\\n\\n\\n\\nSupratim Nag\\n\\nHowrah,West Bengal, India\\n\\n\\uf10b (+91) 8420945255 | snsupratim@gmail.com | https://github.com/snsupratim | snsupratim-portfolio |  https://www.linkedin.com/in/snsupratim\\uf08c\\n\\n\\n\\nSummary ---------------------------------------------------------------------------------\\n\\n\\n\\nEnthusiastic and detail-oriented B.Tech student in Computer Science and Engineering with a specialization in Artificial Intelligence and Machine Learning. Actively learning machine learning, deep learning, NLP, and generative AI techniques. Also worked with various tech stack to built full-stack web application .\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEducation ----------------------------------------------------------------------------------\\n\\n\\n\\nMCKV Institute of Engineering \\n\\nHowrah,West Bengal, India \\n\\nB.Tech in CSE with specializing in AI/ML\\n\\nOctober 2022  June 2026* \\n\\n• 9.56/10 (3rd  year 2nd sem SGPA)\\n\\n• Relevant Course : Machine Learning , Artificial Intelligence , High Performance Computing , NVIDIA CUDA ,\\n\\nCloud Computing , Data Mining , SpringBoot ,Hibernate etc.\\n\\n\\n\\nEducation ----------------------------------------------------------------------------------\\n\\n\\n\\nMCKV Institute of Engineering \\n\\nHowrah,West Bengal, India \\n\\nB.Tech in CSE with specializing in AI/ML\\n\\nOctober 2022  June 2026* \\n\\n• 9.56/10 (3rd  year 2nd sem SGPA)\\n\\n• Relevant Course : Machine Learning , Artificial Intelligence , High Performance Computing , NVIDIA CUDA ,\\n\\nCloud Computing , Data Mining , SpringBoot ,Hibernate etc.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTechnical Skills ----------------------------------------------------------------------------\\n\\n\\n\\nStrongest Areas    :              Machine Learning, Deep Learning, Data Mining, Data Analysis, Generative AI, Full-stack Web Application,NLP,LLMs.\\n\\nProgramming Languages :  C/C++,Python,Go,Java,JavaScript,Typescript,  CUDA C , \\n\\nLibraries/Frameworks:     TensorFlow, PyTorch, Scikit-learn, HuggingFace, Flask,  Streamlit, OpenCV, NLTK, LangChain,Hibernate,Springboot\\n\\nTools :                                 Git, GitHub, Docker, Jupyter , HuggingFace, MLflow, Colab, Cursor\\n\\nDatabase  :                         MongoDB, Firebase, PostgreSQL, MySQL , SupaBase\\n\\nPlatforms :                             Render, AWS ,Vercel\\n\\n\\n\\nTechnical Skills ----------------------------------------------------------------------------\\n\\n\\n\\nStrongest Areas    :              Machine Learning, Deep Learning, Data Mining, Data Analysis, Generative AI, Full-stack Web Application,NLP,LLMs.\\n\\nProgramming Languages :  C/C++,Python,Go,Java,JavaScript,Typescript,  CUDA C , \\n\\nLibraries/Frameworks:     TensorFlow, PyTorch, Scikit-learn, HuggingFace, Flask,  Streamlit, OpenCV, NLTK, LangChain,Hibernate,Springboot\\n\\nTools :                                 Git, GitHub, Docker, Jupyter , HuggingFace, MLflow, Colab, Cursor\\n\\nDatabase  :                         MongoDB, Firebase, PostgreSQL, MySQL , SupaBase\\n\\nPlatforms :                             Render, AWS ,Vercel\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProjects   ------------------------------------------------------------------------------------- \\n\\n\\n\\nCrop-Sisease Detection\\n\\nGoogle Colab,\\n\\nDETECTED CROP DISEASE USING PYTORCH & RESNET-50\\n\\nFlask,MERN Stack \\n\\n• Built an web application to detect crop disease prediction by uploading disease images & participated in IIT-BHU Eco-Hackthon .\\n\\n\\n\\nGenerative AI\\n\\nPython,Flask\\n\\nBuild an AI Chatbot with LLMs ( Gemini)\\n\\nStreamlit,Render\\n\\n• An AI Chatbot where user can  provide their own knowledge base to train the llms as per their requirement.\\n\\n\\n\\nProjects   ------------------------------------------------------------------------------------- \\n\\n\\n\\nCrop-Sisease Detection\\n\\nGoogle Colab,\\n\\nDETECTED CROP DISEASE USING PYTORCH & RESNET-50\\n\\nFlask,MERN Stack \\n\\n• Built an web application to detect crop disease prediction by uploading disease images & participated in IIT-BHU Eco-Hackthon .\\n\\n\\n\\nGenerative AI\\n\\nPython,Flask\\n\\nBuild an AI Chatbot with LLMs ( Gemini)\\n\\nStreamlit,Render\\n\\n• An AI Chatbot where user can  provide their own knowledge base to train the llms as per their requirement.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nResearch Experience-----------------------------------------------------------------------\\n\\n\\n\\nSolution for Healthcare Data Interoperability : \\n\\nDigital Health Symposium at IIT Kharagpur,2023 \\n\\nADDRESSING DATA INTEROPERABILITY\\n\\n\\n\\n• Presented a poster at the IIT Kharagpur event to explain my solution how to enhance data interoperability in Electronic healthcare data.\\n\\n\\n\\nResearch Assistant on Explainable Network Intrusion Detection Systems:  \\n\\n\\n\\nADDRESSING DATA INTEROPERABILITY \\t\\t\\t\\t                                                                             MCKV Institute of Engineering\\n\\n \\n\\n• Conducted research addressing the challenges of interoperability and explain-ability in Deep Learning models applied to Network Intrusion Detection (NID) systems.         \\n\\n• Utilized benchmark datasets NSL-KDD and UNSW-NB15 to evaluate the performance of the proposed model.\\n\\nResearch Experience-----------------------------------------------------------------------\\n\\n\\n\\nSolution for Healthcare Data Interoperability : \\n\\nDigital Health Symposium at IIT Kharagpur,2023 \\n\\nADDRESSING DATA INTEROPERABILITY\\n\\n\\n\\n• Presented a poster at the IIT Kharagpur event to explain my solution how to enhance data interoperability in Electronic healthcare data.\\n\\n\\n\\nResearch Assistant on Explainable Network Intrusion Detection Systems:  \\n\\n\\n\\nADDRESSING DATA INTEROPERABILITY \\t\\t\\t\\t                                                                             MCKV Institute of Engineering\\n\\n \\n\\n• Conducted research addressing the challenges of interoperability and explain-ability in Deep Learning models applied to Network Intrusion Detection (NID) systems.         \\n\\n• Utilized benchmark datasets NSL-KDD and UNSW-NB15 to evaluate the performance of the proposed model.\\n\\n\\n\\nExtraa-Curricular Activities -----------------------------------------------------------------\\n\\n\\n\\n•  Actively play cricket and basketball in my free time, enhancing teamwork and strategic thinking.\\n\\n•  Create YouTube content focused on the technical domain, sharing knowledge and helping others learn.\\n\\n•  Provide private tuition, mentoring students and improving their academic performance.\\n\\n•  Engaged in social work, including cloth and food donation drives to support underprivileged communities.\\n\\n•  Participates in  coding competitions and Hackathons.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nExtraa-Curricular Activities -----------------------------------------------------------------\\n\\n\\n\\n•  Actively play cricket and basketball in my free time, enhancing teamwork and strategic thinking.\\n\\n•  Create YouTube content focused on the technical domain, sharing knowledge and helping others learn.\\n\\n•  Provide private tuition, mentoring students and improving their academic performance.\\n\\n•  Engaged in social work, including cloth and food donation drives to support underprivileged communities.\\n\\n•  Participates in  coding competitions and Hackathons.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCertificates    ----------------------------------------------------------------------------------\\n\\n\\n\\n•  Python for Data Science - Udemy\\n\\n•  Data Analytics - LearnTube\\n\\n•  IoT Workshop Certificates\\n\\n•  Artificial Intelligence - IBM SkillsBuild\\n\\n\\n\\n\\n\\nCertificates    ----------------------------------------------------------------------------------\\n\\n\\n\\n•  Python for Data Science - Udemy\\n\\n•  Data Analytics - LearnTube\\n\\n•  IoT Workshop Certificates\\n\\n•  Artificial Intelligence - IBM SkillsBuild')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bj9Ylj4mrtm",
        "outputId": "97a11c58-f617-4587-8d7a-b45768605783"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/docs/SUPRATIMNAG_AIML.docx'}, page_content='Supratim Nag\\n\\nHowrah,West Bengal, India\\n\\n\\uf10b (+91) 8420945255 | snsupratim@gmail.com | https://github.com/snsupratim | snsupratim-portfolio |  https://www.linkedin.com/in/snsupratim\\uf08c\\n\\n\\n\\nSummary ---------------------------------------------------------------------------------\\n\\n\\n\\nEnthusiastic and detail-oriented B.Tech student in Computer Science and Engineering with a specialization in Artificial Intelligence and Machine Learning. Actively learning machine learning, deep learning, NLP, and generative AI techniques. Also worked with various tech stack to built full-stack web application .\\n\\n\\n\\nSupratim Nag\\n\\nHowrah,West Bengal, India\\n\\n\\uf10b (+91) 8420945255 | snsupratim@gmail.com | https://github.com/snsupratim | snsupratim-portfolio |  https://www.linkedin.com/in/snsupratim\\uf08c\\n\\n\\n\\nSummary ---------------------------------------------------------------------------------')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "splits[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oEFMSgYnI11",
        "outputId": "721b96d8-cc55-4564-b564-8802b4002cc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded 5 from folder\n",
            "splitted documents into 30 chunks\n"
          ]
        }
      ],
      "source": [
        "def load_documents(folder_path : str)-> List[Document]:\n",
        "  documnets=[]\n",
        "  for filename in os.listdir(folder_path):\n",
        "    file_path=os.path.join(folder_path,filename)\n",
        "    if filename.endswith('.pdf'):\n",
        "      loader=PyPDFLoader(file_path)\n",
        "    elif filename.endswith('.docx'):\n",
        "      loader=Docx2txtLoader(file_path)\n",
        "    else:\n",
        "      print(f\"unsupported file type : {filename}\")\n",
        "      continue\n",
        "    documents.extend(loader.load())\n",
        "  return documents\n",
        "\n",
        "folder_path='/content/docs'\n",
        "documents=load_documents(folder_path)\n",
        "print(f\"loaded {len(documents)} from folder\")\n",
        "\n",
        "splits=text_splitter.split_documents(documents)\n",
        "print(f\"splitted documents into {len(splits)} chunks\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGNuGx6XtI6y",
        "outputId": "39c3cf47-fc76-4792-ad84-c70e7bdcf764"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'producer': '', 'creator': 'WPS Writer', 'creationdate': '2024-12-30T16:33:57+05:30', 'author': 'SUPRATIM NAG', 'comments': '', 'company': '', 'keywords': '', 'moddate': '2024-12-30T16:33:57+05:30', 'sourcemodified': \"D:20241230163357+05'30'\", 'subject': '', 'title': '', 'trapped': '/False', 'source': '/content/docs/cv-aiml-intern.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Supratim Nag\\nHowrah,West Bengal, India\\n(+91) 8420945255 | snsupratim@gmail.com | https://github.com/snsupratim | snsupratim-portfolio | https://www.linkedin.com/in/snsupratim\\nObjective -------------------------------------------------------------------\\nEnthusiastic and detail-oriented B.Tech student in Computer Science and Engineering with a specialization in Artificial\\nIntelligence and Machine Learning. Actively learning machine learning, deep learning, NLP, and generative AI\\ntechniques. Seeking an internship to apply my technical skills, enhance my knowledge, and contribute to innovative\\nprojects.\\nEducation ------------------------------------------------------------------\\nMCKV Institute of Engineering\\nHowrah,West Bengal, India\\nB.Tech in CSE with specializing in AI/ML\\nOctober 2022 - June 2026*\\n• 8.88/10 (2nd year YGPA)\\n• Relevant Course : Machine Learning , Artificial Intelligence , High Performance Computing , NVIDIA CUDA, Data\\nStructure & Algorithm.\\nTechnical Skills -----------------------------------------------------------\\nStrongest Areas : Machine Learning, Deep Learning, Data Structures, NLP, Model Optimization\\nProgramming Languages : C/C++,Python,Go,R.Java,JavaScript.\\nLibraries/Frameworks: TensorFlow, PyTorch, Scikit-learn,HuggingFace,Flask, Django, Streamlit, OpenCV, NLTK,\\nTools : Git, GitHub, Docker, Jupyter Notebook, HuggingFace, MLflow, Google Colab, Kubernetes\\nDatabase : MongoDB, Firebase, PostgreSQL,MySQL\\nPlatforms : Render, HuggingFace,AWS .\\nProjects---------------------------------------------------------------------\\nML Showcase\\nPython,Flask\\nCOLLECTION OF MY ML MODELS\\nGithub\\n• Designed an web application where people can use my ML Models.\\n• https://models-hub.onrender.com\\nDrone-Jamming-Detection\\nGoogle Colab\\nDETECTING JAMMED DRONE SIGNAL (software)\\nGithub\\n• Built an web application to detect which type of signal is jammed .\\nResearch Experience-----------------------------------------------------\\nSolution for Healthcare Data Interoperability :\\nDigital Health Symposium at IIT Kharagpur,2023\\nADDRESSING DATA INTEROPERABILITY\\n• Presented a poster at the IIT Kharagpur event to explain my solution how to enhance data interoperability in Electronic\\nhealthcare data.\\nResearch Assistant on Explainable Network Intrusion Detection Systems:\\nADDRESSING DATA INTEROPERABILITY MCKV Institute of Engineering\\n• Conducted research addressing the challenges of interoperability and explain-ability in Deep Learning models applied\\nto Network Intrusion Detection (NID) systems.\\n• Utilized benchmark datasets NSL-KDD and UNSW-NB15 to evaluate the performance of the proposed model.\\n• Focused on implementing attention mechanisms coupled with a multi-output Deep Learning strategy to enhance\\nclassification accuracy and explain-ability.')"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCilWgP5tMmN",
        "outputId": "bfbd02be-3b72-46e9-cb15-e2f001f27890"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/docs/SUPRATIMNAG_AIML.docx'}, page_content='Tools :                                 Git, GitHub, Docker, Jupyter , HuggingFace, MLflow, Colab, Cursor\\n\\nDatabase  :                         MongoDB, Firebase, PostgreSQL, MySQL , SupaBase\\n\\nPlatforms :                             Render, AWS ,Vercel\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProjects   ------------------------------------------------------------------------------------- \\n\\n\\n\\nCrop-Sisease Detection\\n\\nGoogle Colab,\\n\\nDETECTED CROP DISEASE USING PYTORCH & RESNET-50\\n\\nFlask,MERN Stack \\n\\n• Built an web application to detect crop disease prediction by uploading disease images & participated in IIT-BHU Eco-Hackthon .\\n\\n\\n\\nGenerative AI\\n\\nPython,Flask\\n\\nBuild an AI Chatbot with LLMs ( Gemini)\\n\\nStreamlit,Render\\n\\n• An AI Chatbot where user can  provide their own knowledge base to train the llms as per their requirement.\\n\\n\\n\\nProjects   ------------------------------------------------------------------------------------- \\n\\n\\n\\nCrop-Sisease Detection\\n\\nGoogle Colab,')"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "splits[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG6ZVjF7OLK1"
      },
      "source": [
        "\n",
        "###**Creating Embeddings**\n",
        "- Using GoogleAI Embeddings\n",
        "- Using SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFFBX_nVtR-O",
        "outputId": "b333b4c3-2d9a-4e01-ccb1-6ccdfa07c236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "created embedding for 30 documents chunks\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "document_embedding=embedding.embed_documents([split.page_content for split in splits])\n",
        "print(f\"created embedding for {len(document_embedding)} documents chunks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srsOkJA6OM-n"
      },
      "source": [
        "\n",
        "###**Setting Up the Vector Store**\n",
        "- Creating the Vector Store\n",
        "- Performing Similarity Search\n",
        "- Creating a Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1e986bVvm58",
        "outputId": "e1dd4070-f617-4aad-af32-084acbc35217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vector store created and persisted to './chroma_db' \n"
          ]
        }
      ],
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "embedding_function=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "collection_name=\"my_collection\"\n",
        "vectorstore=Chroma.from_documents(\n",
        "    collection_name=collection_name,\n",
        "    documents=splits,\n",
        "    embedding=embedding_function,\n",
        "    persist_directory=\"./chroma_db\"\n",
        ")\n",
        "\n",
        "print(\"vector store created and persisted to './chroma_db' \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMqBIjYAwU8y",
        "outputId": "da678fe3-fef7-4459-fb9d-bf633d46571f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Top 2 most relevant search for the query : 'what is the resume summary?' \n",
            " \n",
            "result 1:\n",
            "source: /content/docs/SUPRATIMNAG_AIML.docx\n",
            "content : Summary ---------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Enthusiastic and detail-oriented B.Tech student in Computer Science and Engineering with a specialization in Artificial Intelligence and Machine Learning. Actively learning machine learning, deep learning, NLP, and generative AI techniques. Also worked with various tech stack to built full-stack web application .\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Education ----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "MCKV Institute of Engineering \n",
            "\n",
            "Howrah,West Bengal, India \n",
            "\n",
            "B.Tech in CSE with specializing in AI/ML\n",
            "\n",
            "October 2022  June 2026* \n",
            "\n",
            "• 9.56/10 (3rd  year 2nd sem SGPA)\n",
            "\n",
            "• Relevant Course : Machine Learning , Artificial Intelligence , High Performance Computing , NVIDIA CUDA ,\n",
            "\n",
            "Cloud Computing , Data Mining , SpringBoot ,Hibernate etc.\n",
            "\n",
            "\n",
            "\n",
            "Education ----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "MCKV Institute of Engineering\n",
            "\n",
            "result 2:\n",
            "source: /content/docs/SUPRATIMNAG_AIML.docx\n",
            "content : Summary ---------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Enthusiastic and detail-oriented B.Tech student in Computer Science and Engineering with a specialization in Artificial Intelligence and Machine Learning. Actively learning machine learning, deep learning, NLP, and generative AI techniques. Also worked with various tech stack to built full-stack web application .\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Education ----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "MCKV Institute of Engineering \n",
            "\n",
            "Howrah,West Bengal, India \n",
            "\n",
            "B.Tech in CSE with specializing in AI/ML\n",
            "\n",
            "October 2022  June 2026* \n",
            "\n",
            "• 9.56/10 (3rd  year 2nd sem SGPA)\n",
            "\n",
            "• Relevant Course : Machine Learning , Artificial Intelligence , High Performance Computing , NVIDIA CUDA ,\n",
            "\n",
            "Cloud Computing , Data Mining , SpringBoot ,Hibernate etc.\n",
            "\n",
            "\n",
            "\n",
            "Education ----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "MCKV Institute of Engineering\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query=\"what is the resume summary?\"\n",
        "\n",
        "search_results=vectorstore.similarity_search(query,k=2)\n",
        "print(f\"\\n Top 2 most relevant search for the query : '{query}' \\n \")\n",
        "for i,result in enumerate(search_results,1):\n",
        "  print(f\"result {i}:\")\n",
        "  print(f\"source: {result.metadata.get('source','Unknown')}\")\n",
        "  print(f\"content : {result.page_content}\")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydsl2l7txjsy",
        "outputId": "f95fead7-ac2e-42b8-9f53-ced32510505a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(id='a1c1ac47-2cc4-4842-8ff8-09c59d51a548', metadata={'source': '/content/docs/SUPRATIMNAG_AIML.docx'}, page_content='Summary ---------------------------------------------------------------------------------\\n\\n\\n\\nEnthusiastic and detail-oriented B.Tech student in Computer Science and Engineering with a specialization in Artificial Intelligence and Machine Learning. Actively learning machine learning, deep learning, NLP, and generative AI techniques. Also worked with various tech stack to built full-stack web application .\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEducation ----------------------------------------------------------------------------------\\n\\n\\n\\nMCKV Institute of Engineering \\n\\nHowrah,West Bengal, India \\n\\nB.Tech in CSE with specializing in AI/ML\\n\\nOctober 2022  June 2026* \\n\\n• 9.56/10 (3rd  year 2nd sem SGPA)\\n\\n• Relevant Course : Machine Learning , Artificial Intelligence , High Performance Computing , NVIDIA CUDA ,\\n\\nCloud Computing , Data Mining , SpringBoot ,Hibernate etc.\\n\\n\\n\\nEducation ----------------------------------------------------------------------------------\\n\\n\\n\\nMCKV Institute of Engineering'), Document(id='bcc5e833-3d05-4aa7-bdf4-8cd8bc1a88c7', metadata={'source': '/content/docs/SUPRATIMNAG_AIML.docx'}, page_content='Summary ---------------------------------------------------------------------------------\\n\\n\\n\\nEnthusiastic and detail-oriented B.Tech student in Computer Science and Engineering with a specialization in Artificial Intelligence and Machine Learning. Actively learning machine learning, deep learning, NLP, and generative AI techniques. Also worked with various tech stack to built full-stack web application .\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEducation ----------------------------------------------------------------------------------\\n\\n\\n\\nMCKV Institute of Engineering \\n\\nHowrah,West Bengal, India \\n\\nB.Tech in CSE with specializing in AI/ML\\n\\nOctober 2022  June 2026* \\n\\n• 9.56/10 (3rd  year 2nd sem SGPA)\\n\\n• Relevant Course : Machine Learning , Artificial Intelligence , High Performance Computing , NVIDIA CUDA ,\\n\\nCloud Computing , Data Mining , SpringBoot ,Hibernate etc.\\n\\n\\n\\nEducation ----------------------------------------------------------------------------------\\n\\n\\n\\nMCKV Institute of Engineering')]\n"
          ]
        }
      ],
      "source": [
        "retriever=vectorstore.as_retriever(search_kwargs={\"k\":2})\n",
        "retriever_results=retriever.invoke(\"who is the candidate whose cv we are seeing?\")\n",
        "print(retriever_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOTwj2MEOO7j"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###**Building the RAG Chain**\n",
        "- Creating the RAG Chain\n",
        "- Using the RAG Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lwUCOrF4yKO3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "template=\"\"\"\n",
        "Answer the question based only on the following context:\n",
        "{context}\n",
        "Question:{question}\n",
        "Answer: \"\"\"\n",
        "\n",
        "\n",
        "prompt=ChatPromptTemplate.from_template(template)\n",
        "\n",
        "def docs2str(docs):\n",
        "  return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "rag_chain=(\n",
        "    {\"context\":retriever | docs2str,\"question\":RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    |StrOutputParser()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY1Appk3zabH",
        "outputId": "b1e436fd-09ea-471d-fe3a-5af5500d6505"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "question: which college does the person studies?\n",
            "response: MCKV Institute of Engineering\n"
          ]
        }
      ],
      "source": [
        "question=\"which college does the person studies?\"\n",
        "response=rag_chain.invoke(question)\n",
        "print(f\"question: {question}\")\n",
        "print(f\"response: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIjUc_EqOQsV"
      },
      "source": [
        "\n",
        "###**Handling Follow-Up Questions**\n",
        "- Creating a History-Aware Retriever\n",
        "- Using the History-Aware RAG Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX3EX_tj0GfU",
        "outputId": "ac946c4f-7caa-4ea1-c9db-8557482a4a9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is his CGPA?\n"
          ]
        }
      ],
      "source": [
        "from decimal import Context\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "\n",
        "context_q_system_prompt=\"\"\"\n",
        "Given a chat history and latest user question\n",
        " which might refernce context in chat history,\n",
        "formulate a standalone quesion which can be understood without the chat history.\n",
        "Do not answer the question,\n",
        "just formulate it if needed and otherwise return as it is.\n",
        "\"\"\"\n",
        "\n",
        "context_q_prompt=ChatPromptTemplate.from_messages([\n",
        "    (\"system\",context_q_system_prompt),\n",
        "    MessagesPlaceholder(\"chat_history\"),\n",
        "    (\"human\",\"{input}\"),\n",
        "])\n",
        "\n",
        "context_chain=context_q_prompt | llm | StrOutputParser()\n",
        "print(context_chain.invoke({\"input\":\"what does his cgpa? \",\"chat_history\":[]}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Ib_keJmA19p2"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "history_aware_retriever=create_history_aware_retriever(\n",
        "    llm,retriever,context_q_prompt\n",
        ")\n",
        "\n",
        "qa_prompt=ChatPromptTemplate.from_messages([\n",
        "     (\"system\",\"you are a helpfull AI assistant. use following context to answer the user's question.\"),\n",
        "     (\"system\",\"Context:{context}\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"human\",\"{input}\"),\n",
        "])\n",
        "\n",
        "question_answer_chain=create_stuff_documents_chain(llm,qa_prompt)\n",
        "rag_chain=create_retrieval_chain(history_aware_retriever,question_answer_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ajt8dhr325CI",
        "outputId": "6113f3bd-6f49-47c4-adfc-88a67a65332c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "where was his college?\n",
            "The student attended MCKV Institute of Engineering in Howrah, West Bengal, India.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage,AIMessage\n",
        "\n",
        "chat_history=[]\n",
        "question1=\"where was his college?\"\n",
        "answer1=rag_chain.invoke({\"input\":question1,\"chat_history\":chat_history})['answer']\n",
        "chat_history.extend([\n",
        "    HumanMessage(content=question1),\n",
        "    AIMessage(content=answer1)\n",
        "])\n",
        "\n",
        "print(question1)\n",
        "print(answer1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBUDqmSe3vyS",
        "outputId": "ece25d79-317f-4003-951a-271a271d39e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "what was his sgpa and his college name?\n",
            "His most recent SGPA (Semester Grade Point Average) was 9.56/10.  His college is MCKV Institute of Engineering in Howrah, West Bengal, India.\n"
          ]
        }
      ],
      "source": [
        "question2=\"what was his sgpa and his college name?\"\n",
        "answer2=rag_chain.invoke({\"input\":question2,\"chat_history\":chat_history})['answer']\n",
        "chat_history.extend([\n",
        "    HumanMessage(content=question2),\n",
        "    AIMessage(content=answer2)\n",
        "])\n",
        "\n",
        "print(question2)\n",
        "print(answer2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
